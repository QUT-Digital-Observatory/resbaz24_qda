{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QDA 2 - Accessing AI\n",
    "\n",
    "In this notebook we'll take some prompts and generate a response using a commercial AI model via their API. We'll be using Google Gemini for but we also provide some code to use OpenAI's Chat GPT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting a prompt\n",
    "\n",
    "We made a prompt and saved it as `outputs/test_prompt.txt` last time let's see open this and send it to an AI model and get the response. `GeminiAIModel` is our little helper around the API which handles things like getting a list of models, tracking costs disabling all of the content filters. We also adopt an output format in common with an OpenAI version so we can easily switched between models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tokens: 227, output tokens: 354\n",
      "gemini-1.5-flash-002 responded which cost us: $0.00\n"
     ]
    }
   ],
   "source": [
    "from resbaz24.genai_google import GeminiAIModel\n",
    "\n",
    "with open('outputs/test_prompt.txt', 'r', encoding='utf-8') as f:\n",
    "    prompt_str = f.read()\n",
    "\n",
    "janky = GeminiAIModel() # our nickname for Germini\n",
    "\n",
    "ai_response = janky.get_completion(prompt=prompt_str) # This returns a CostedResponse\n",
    "# This will take a little while to run - then let's print the cost, and save the output to a file\n",
    "if ai_response.response is None:\n",
    "    raise ValueError(\"No response was generated\")\n",
    "print(f\"{ai_response.model} responded which cost us: ${ai_response.cost:.2f}\")\n",
    "with open('outputs/test_response.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(ai_response.response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting serious\n",
    "\n",
    "Okay, but that's no different than what we could have done by pasting it into the web page. Let's go for a coding task, and this time use JSON as the output format so we can parse the data - and reassemble back with the original ids (remember the prompt doesn't have them).\n",
    "\n",
    "We need to go back to the dataset and get the dataframe, and make new documents, get a response and write the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tokens: 278, output tokens: 67\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from resbaz24.documents import SimpleDocument, documents_to_prompts\n",
    "\n",
    "data_submissions = pd.read_parquet('2024_qld_election_reddit_dataset/submissions.parquet')\n",
    "docs = [SimpleDocument(id=row.id, text=f\"{row.title}: {row.selftext}\") for _, row in data_submissions[data_submissions.selftext.notna()].head(5).iterrows()]\n",
    "instruction_prompt = \"Consider the following Reddit submissions and code them according to two criteria: 1) Whether the submission is about the housing crisis, and 2) Where the submission author is a nerd, or not. Output a JSON list of objects where each object has boolean properties 'housing_crisis' and 'is_nerd'.\\n\"\n",
    "full_prompts = documents_to_prompts(data=docs, prompt=instruction_prompt, max_words=1000)\n",
    "with open('outputs/json_prompt.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(full_prompts[0].prompt)\n",
    "ai_response = janky.get_completion(prompt=full_prompts[0].prompt, json_mode=True)\n",
    "if ai_response.response is None:\n",
    "    raise ValueError(\"No response was generated\")\n",
    "with open('outputs/json_response.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(ai_response.response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parsing JSON data\n",
    "\n",
    "That's great but the point of JSON is that we can parse it directly back into Python. Also, our JSON doesn't have the original ids. Remember that the ids are in the .idlist property from the `PromptDocument` object. So let's get everything into a proper Python object, and then dump it back out as JSON to have a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>permalink</th>\n",
       "      <th>selftext</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SCOOBASTEVE</td>\n",
       "      <td>1genh6z</td>\n",
       "      <td>Interested in hearing from people who live/hav...</td>\n",
       "      <td>/r/brisbane/comments/1genh6z/interested_in_hea...</td>\n",
       "      <td>I went for a drive along the Centenary a few w...</td>\n",
       "      <td>2024-10-29 05:36:36</td>\n",
       "      <td>brisbane</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ConanTheAquarian</td>\n",
       "      <td>1gegdid</td>\n",
       "      <td>Five new Brisbane bus routes, changes to dozen...</td>\n",
       "      <td>/r/brisbane/comments/1gegdid/five_new_brisbane...</td>\n",
       "      <td>Buses could be more frequent, more reliable, l...</td>\n",
       "      <td>2024-10-28 23:22:40</td>\n",
       "      <td>brisbane</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UnlikelyBicycle2559</td>\n",
       "      <td>1gefear</td>\n",
       "      <td>Buying in Bris vs Melb?</td>\n",
       "      <td>/r/brisbane/comments/1gefear/buying_in_bris_vs...</td>\n",
       "      <td>TLDR: Pros and cons of moving to Melb because ...</td>\n",
       "      <td>2024-10-28 22:39:17</td>\n",
       "      <td>brisbane</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Grugly</td>\n",
       "      <td>1ge2t3w</td>\n",
       "      <td>Did you change your mind after voting early?</td>\n",
       "      <td>/r/brisbane/comments/1ge2t3w/did_you_change_yo...</td>\n",
       "      <td>I'm a bit of a data nerd and reviewing the ele...</td>\n",
       "      <td>2024-10-28 14:02:14</td>\n",
       "      <td>brisbane</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wonderful_Alps5959</td>\n",
       "      <td>1gdyvc3</td>\n",
       "      <td>Is Woodridge that bad? FHB</td>\n",
       "      <td>/r/brisbane/comments/1gdyvc3/is_woodridge_that...</td>\n",
       "      <td>Looking around Brisbane as I’m FHB - and have ...</td>\n",
       "      <td>2024-10-28 10:37:55</td>\n",
       "      <td>brisbane</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                author       id  \\\n",
       "1          SCOOBASTEVE  1genh6z   \n",
       "3     ConanTheAquarian  1gegdid   \n",
       "4  UnlikelyBicycle2559  1gefear   \n",
       "6               Grugly  1ge2t3w   \n",
       "7   Wonderful_Alps5959  1gdyvc3   \n",
       "\n",
       "                                               title  \\\n",
       "1  Interested in hearing from people who live/hav...   \n",
       "3  Five new Brisbane bus routes, changes to dozen...   \n",
       "4                            Buying in Bris vs Melb?   \n",
       "6       Did you change your mind after voting early?   \n",
       "7                         Is Woodridge that bad? FHB   \n",
       "\n",
       "                                           permalink  \\\n",
       "1  /r/brisbane/comments/1genh6z/interested_in_hea...   \n",
       "3  /r/brisbane/comments/1gegdid/five_new_brisbane...   \n",
       "4  /r/brisbane/comments/1gefear/buying_in_bris_vs...   \n",
       "6  /r/brisbane/comments/1ge2t3w/did_you_change_yo...   \n",
       "7  /r/brisbane/comments/1gdyvc3/is_woodridge_that...   \n",
       "\n",
       "                                            selftext         created_utc  \\\n",
       "1  I went for a drive along the Centenary a few w... 2024-10-29 05:36:36   \n",
       "3  Buses could be more frequent, more reliable, l... 2024-10-28 23:22:40   \n",
       "4  TLDR: Pros and cons of moving to Melb because ... 2024-10-28 22:39:17   \n",
       "6  I'm a bit of a data nerd and reviewing the ele... 2024-10-28 14:02:14   \n",
       "7  Looking around Brisbane as I’m FHB - and have ... 2024-10-28 10:37:55   \n",
       "\n",
       "  subreddit  num_comments  \n",
       "1  brisbane            23  \n",
       "3  brisbane            31  \n",
       "4  brisbane            19  \n",
       "6  brisbane            23  \n",
       "7  brisbane            36  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "assert ai_response.response is not None # because python notebooks forget we trapped this error in the above cell\n",
    "decoded_json = json.loads(ai_response.response)\n",
    "for i in range(len(decoded_json)):\n",
    "    decoded_json[i]['id'] = full_prompts[0].idlist[i] # add the id from our original data\n",
    "with open('outputs/json_response_decoded.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(decoded_json, f, indent=2) # This indent arg makes the file human-readable\n",
    "data_submissions[data_submissions.selftext.notna()].head(5) # Let's see the original data for comparison\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making a CSV\n",
    "\n",
    "CSV is awful but it's a an easy way just to get some data into a spreadsheet so we can view it easily. Let's make a CSV file with the ids, the title, selftext, and columns for the flags we got from the AI model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = data_submissions[data_submissions.selftext.notna()].head(5)\n",
    "json_df = pd.DataFrame(decoded_json) # make a little dataframe from our decoded JSON\n",
    "if len(main_df) != len(json_df):\n",
    "    raise ValueError(\"Dataframes are not the same length\")\n",
    "result_df = main_df.merge(\n",
    "    json_df[['id', 'housing_crisis', 'is_nerd']], \n",
    "    on='id', \n",
    "    how='left'\n",
    ")\n",
    "final_df = result_df[['id', 'title', 'selftext', 'housing_crisis', 'is_nerd']]\n",
    "final_df.to_csv('outputs/result_df.csv', index=False) # save to a CSV file with pandas\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
